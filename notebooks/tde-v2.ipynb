{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDE-v2 Dataset Cookbook\n",
    "\n",
    "This cookbooks severs as the preparation for the TDE-v2 dataset for the Chat-Transform project. It refactored the original dataset from Yeye-He's [repo](https://github.com/Yeye-He/Transform-Data-by-Example/tree/master/Benchmark) into a fine-tuning `Alpaca` format that is compatible with the [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = '../data/TDE-v2/'\n",
    "data_frames = []\n",
    "\n",
    "# Load all JSON files in the directory and convert to DataFrame\n",
    "for subdir, _, files in os.walk(data_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                df = pd.json_normalize(json.load(f),\n",
    "                                       meta=[['context', 'input'], ['context', 'output']])\n",
    "                \n",
    "                test_fp = file_path.replace(data_directory, \"\")\n",
    "                df['test_path'] = os.path.splitext(test_fp)[0]  # remove file extension\n",
    "                data_frames.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "df_all = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# split the function from field 'instruction'\n",
    "df_all['function'] = df_all['instruction'].apply(lambda x: x.split(':')[0].strip())\n",
    "\n",
    "# check the shape of the dataframe\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>instruction</th>\n",
       "      <th>tuples</th>\n",
       "      <th>context.input</th>\n",
       "      <th>context.output</th>\n",
       "      <th>test_path</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transform first and last names into username</td>\n",
       "      <td>format(): Combine first letter of first name w...</td>\n",
       "      <td>[{'input': 'john\tsmith', 'output': 'jsmith'}, ...</td>\n",
       "      <td>First and last names separated by a tab charac...</td>\n",
       "      <td>Username created by combining the first letter...</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>format()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract name of actor/actress</td>\n",
       "      <td>extract(): extract name of actor/actress from ...</td>\n",
       "      <td>[{'input': '* '''1953 [[Meena Kumari]] – ''[[B...</td>\n",
       "      <td>text format containing movie details</td>\n",
       "      <td>extracted name of actor/actress</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>extract()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract character names from wiki-style list</td>\n",
       "      <td>extract(): Extract the character name from the...</td>\n",
       "      <td>[{'input': '* '''1953 [[Meena Kumari]] – ''[[B...</td>\n",
       "      <td>Wiki-style list item containing actor and char...</td>\n",
       "      <td>Character name extracted from the input</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>extract()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>format date of birth</td>\n",
       "      <td>format(): convert YYYYMMDD to MM-DD-YYYY</td>\n",
       "      <td>[{'input': '19610223', 'output': '02-23-1961'}...</td>\n",
       "      <td>date in YYYYMMDD format</td>\n",
       "      <td>formatted date in MM-DD-YYYY</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>format()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract and format movie titles</td>\n",
       "      <td>transform(): Extract the movie title from the ...</td>\n",
       "      <td>[{'input': '* '''1953 [[Meena Kumari]] – ''[[B...</td>\n",
       "      <td>String containing movie information with title...</td>\n",
       "      <td>Lowercase movie title</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>transform()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           chat  \\\n",
       "0  Transform first and last names into username   \n",
       "1                 Extract name of actor/actress   \n",
       "2  Extract character names from wiki-style list   \n",
       "3                          format date of birth   \n",
       "4               Extract and format movie titles   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  format(): Combine first letter of first name w...   \n",
       "1  extract(): extract name of actor/actress from ...   \n",
       "2  extract(): Extract the character name from the...   \n",
       "3           format(): convert YYYYMMDD to MM-DD-YYYY   \n",
       "4  transform(): Extract the movie title from the ...   \n",
       "\n",
       "                                              tuples  \\\n",
       "0  [{'input': 'john\tsmith', 'output': 'jsmith'}, ...   \n",
       "1  [{'input': '* '''1953 [[Meena Kumari]] – ''[[B...   \n",
       "2  [{'input': '* '''1953 [[Meena Kumari]] – ''[[B...   \n",
       "3  [{'input': '19610223', 'output': '02-23-1961'}...   \n",
       "4  [{'input': '* '''1953 [[Meena Kumari]] – ''[[B...   \n",
       "\n",
       "                                       context.input  \\\n",
       "0  First and last names separated by a tab charac...   \n",
       "1               text format containing movie details   \n",
       "2  Wiki-style list item containing actor and char...   \n",
       "3                            date in YYYYMMDD format   \n",
       "4  String containing movie information with title...   \n",
       "\n",
       "                                      context.output  \\\n",
       "0  Username created by combining the first letter...   \n",
       "1                    extracted name of actor/actress   \n",
       "2            Character name extracted from the input   \n",
       "3                       formatted date in MM-DD-YYYY   \n",
       "4                              Lowercase movie title   \n",
       "\n",
       "                                           test_path     function  \n",
       "0  benchmark-FF-Trifacta-GoogleRefine/example_fil...     format()  \n",
       "1  benchmark-FF-Trifacta-GoogleRefine/example_fil...    extract()  \n",
       "2  benchmark-FF-Trifacta-GoogleRefine/example_fil...    extract()  \n",
       "3  benchmark-FF-Trifacta-GoogleRefine/example_fil...     format()  \n",
       "4  benchmark-FF-Trifacta-GoogleRefine/example_fil...  transform()  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TDE-v2 dataset Data Dictionary\n",
    "\n",
    "- The `chat` field represents a conversation between a user and an AI assistant. It is expected to be the input to the fine-tuned LM.\n",
    "\n",
    "- The `instruction` field represents a coding instruction with API-style `function` name that specifies the transformation type. It is expected to be the target output from the fine-tuned LM.\n",
    "\n",
    "- The `tuples` field represents a list of transformation-pairs, which serves as additional few-shot examples to help the fine-tuned LM to understand the user's intention. Each transformation-pair is a list of tuples, where each tuple contains an input and an output. The context of transformation pairs is stored in `context.input` and `context.output` fields, respectively.\n",
    "\n",
    "- `test_path` refers to the original path of the test case in the TDE dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>instruction</th>\n",
       "      <th>tuples</th>\n",
       "      <th>context.input</th>\n",
       "      <th>context.output</th>\n",
       "      <th>test_path</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chat, instruction, tuples, context.input, context.output, test_path, function]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates of instruction, and sort it\n",
    "df_all[df_all.duplicated(subset=['instruction'], keep=False)].sort_values(by='instruction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract()             57\n",
       "unit_convert()        48\n",
       "format()              45\n",
       "domain_calculate()    34\n",
       "transform()           25\n",
       "domain_map()          17\n",
       "Name: function, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show distribution of function\n",
    "df_all['function'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    226.000000\n",
      "mean       5.575221\n",
      "std        2.232309\n",
      "min        4.000000\n",
      "25%        5.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max       25.000000\n",
      "Name: num_tuples, dtype: float64\n",
      "Total number of tuples:  1260\n"
     ]
    }
   ],
   "source": [
    "# count the number of transformation-pairs in tuples\n",
    "df_all['num_tuples'] = df_all['tuples'].apply(len)\n",
    "print(df_all['num_tuples'].describe()) \n",
    "\n",
    "print(\"Total number of tuples: \", df_all['num_tuples'].sum())\n",
    "# show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# re arrange columns\n",
    "df_all = df_all[['test_path', 'chat', 'instruction', 'context.input', 'context.output', 'tuples']]\n",
    "\n",
    "# sort by test_path\n",
    "df_all.sort_values(by='test_path', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV\n",
    "df_all.to_csv('../data/TDE-v2/tde-v2-all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor to Alpaca Format\n",
    "\n",
    "The fine-tuned LM serves as an AI assistant to translate user chat into the target instruction (chat-to-instruction), with the help of transformation-pairs stored in `tuples` field and the context information stored in `context.input` and `context.output` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chat', 'instruction', 'tuples', 'context.input', 'context.output',\n",
       "       'test_path', 'function'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The number of training pairs in `tuples` field is a hyperparameter to be tuned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>instruction</th>\n",
       "      <th>chat_ctx</th>\n",
       "      <th>train_pairs</th>\n",
       "      <th>test_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>normalize accented string</td>\n",
       "      <td>format(): normalize string by replacing accent...</td>\n",
       "      <td>normalize accented string\\nInput: string with ...</td>\n",
       "      <td>Input: áéíóú\\nOutput: aeiou\\nInput: aeiou\\nOut...</td>\n",
       "      <td>Input: aeío\\nOutput: aeio\\nInput: aeíouíóúz\\nO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>normalize acronyms</td>\n",
       "      <td>format(): map full phrases to their acronyms.</td>\n",
       "      <td>normalize acronyms\\nInput: full phrases with a...</td>\n",
       "      <td>Input: association computing machinery\\nOutput...</td>\n",
       "      <td>Input: special interest group information retr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>normalize movie titles</td>\n",
       "      <td>transform(): normalize movie titles by removin...</td>\n",
       "      <td>normalize movie titles\\nInput: movie titles wi...</td>\n",
       "      <td>Input: Harry Potter 4 aka Harry Potter and the...</td>\n",
       "      <td>Input: The Hunger Games 3 aka the hunger games...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>parse the house area from the description</td>\n",
       "      <td>extract(): extract the house area from the des...</td>\n",
       "      <td>parse the house area from the description\\nInp...</td>\n",
       "      <td>Input: Mar 18 Beautiful One bedroom Available....</td>\n",
       "      <td>Input: Mar 1 Lake Washington, Bellevue $1234 /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>parse rental price from Craigslist listings</td>\n",
       "      <td>extract(): extract the rental price from each ...</td>\n",
       "      <td>parse rental price from Craigslist listings\\nI...</td>\n",
       "      <td>Input: Mar 18 Beautiful One bedroom Available....</td>\n",
       "      <td>Input: Mar 1 Lake Washington, Bellevue $1234 /...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           chat  \\\n",
       "40                    normalize accented string   \n",
       "16                           normalize acronyms   \n",
       "19                       normalize movie titles   \n",
       "5     parse the house area from the description   \n",
       "35  parse rental price from Craigslist listings   \n",
       "\n",
       "                                          instruction  \\\n",
       "40  format(): normalize string by replacing accent...   \n",
       "16      format(): map full phrases to their acronyms.   \n",
       "19  transform(): normalize movie titles by removin...   \n",
       "5   extract(): extract the house area from the des...   \n",
       "35  extract(): extract the rental price from each ...   \n",
       "\n",
       "                                             chat_ctx  \\\n",
       "40  normalize accented string\\nInput: string with ...   \n",
       "16  normalize acronyms\\nInput: full phrases with a...   \n",
       "19  normalize movie titles\\nInput: movie titles wi...   \n",
       "5   parse the house area from the description\\nInp...   \n",
       "35  parse rental price from Craigslist listings\\nI...   \n",
       "\n",
       "                                          train_pairs  \\\n",
       "40  Input: áéíóú\\nOutput: aeiou\\nInput: aeiou\\nOut...   \n",
       "16  Input: association computing machinery\\nOutput...   \n",
       "19  Input: Harry Potter 4 aka Harry Potter and the...   \n",
       "5   Input: Mar 18 Beautiful One bedroom Available....   \n",
       "35  Input: Mar 18 Beautiful One bedroom Available....   \n",
       "\n",
       "                                           test_pairs  \n",
       "40  Input: aeío\\nOutput: aeio\\nInput: aeíouíóúz\\nO...  \n",
       "16  Input: special interest group information retr...  \n",
       "19  Input: The Hunger Games 3 aka the hunger games...  \n",
       "5   Input: Mar 1 Lake Washington, Bellevue $1234 /...  \n",
       "35  Input: Mar 1 Lake Washington, Bellevue $1234 /...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refactor columns based on Alpaca format\n",
    "df_alpaca = df_all.copy()\n",
    "\n",
    "df_alpaca['chat_ctx'] = df_alpaca.apply(\n",
    "    lambda x: x['chat'] + '\\n' +\n",
    "              'Input: ' + x['context.input'] + '\\n' + \n",
    "              'Output: ' + x['context.output'],\n",
    "    axis=1)\n",
    "\n",
    "split_index = 3\n",
    "# only keep the first 3 transformation-pairs for training, align with paper setting\n",
    "\n",
    "df_alpaca['train_pairs'] = df_alpaca['tuples'].apply(lambda x: '\\n'.join([f'Input: {t[\"input\"]}\\nOutput: {t[\"output\"]}' for t in x[:split_index]])) \n",
    "\n",
    "df_alpaca['test_pairs'] = df_alpaca['tuples'].apply(lambda x: '\\n'.join([f'Input: {t[\"input\"]}\\nOutput: {t[\"output\"]}' for t in x[split_index:]])) \n",
    "\n",
    "\n",
    "# drop the original columns\n",
    "df_alpaca.drop(columns=['context.input', 'context.output', 'tuples', 'test_path'], inplace=True)\n",
    "\n",
    "df_alpaca.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Fine-Tuning Dataset\n",
    "\n",
    "Regarding the above dataset, the *dataset description* in `dataset_info.json` of `LLaMA-Factory` should be the following 3 options:\n",
    "\n",
    "1. `tde-o1`: chat-only\n",
    "\n",
    "```json\n",
    "\"tde-o1\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat\", // user chat, no context\n",
    "    \"query\": \"\", \n",
    "    \"response\": \"instruction\", // model response\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "2. `tde-o2`: chat + transformation-pairs\n",
    "\n",
    "```json\n",
    "\"tde-o2\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat\", // user chat\n",
    "    \"query\": \"io_pairs\", // transformation-pairs\n",
    "    \"response\": \"instruction\", // model response\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "3. `tde-o3`: chat + context\n",
    "\n",
    "```json\n",
    "\"tde-o3\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat_ctx\", // user chat + context\n",
    "    \"query\": \"\", // empty\n",
    "    \"response\": \"instruction\", // model response\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "4. `tde-o4`: chat + context + transformation-pairs\n",
    "\n",
    "```json\n",
    "\"tde-o4\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat_ctx\", // user chat + context\n",
    "    \"query\": \"io_pairs\", // transformation-pairs\n",
    "    \"response\": \"instruction\", // model response\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to JSON\n",
    "df_alpaca.to_json('../data/TDE-v2/tde-alpaca.json', orient='records', indent=4, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-sketch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
