{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDE-v2 Dataset Cookbook\n",
    "\n",
    "This cookbooks severs as the preparation for the TDE-v2 dataset for the Chat-Transform project. It refactored the original dataset from Yeye-He's [repo](https://github.com/Yeye-He/Transform-Data-by-Example/tree/master/Benchmark) into a fine-tuning `Alpaca` format that is compatible with the [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = '../data/TDE-v2/'\n",
    "data_frames = []\n",
    "\n",
    "# Load all JSON files in the directory and convert to DataFrame\n",
    "for subdir, _, files in os.walk(data_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                df = pd.json_normalize(json.load(f),\n",
    "                                    meta=[['context', 'input'], ['context', 'output']])\n",
    "                \n",
    "                test_fp = file_path.replace(data_directory, \"\")\n",
    "                df['test_path'] = os.path.splitext(test_fp)[0]  # remove file extension\n",
    "                data_frames.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "df_all = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# split the function from field 'instruction'\n",
    "df_all['function'] = df_all['instruction'].apply(lambda x: x.split(':')[0].strip())\n",
    "\n",
    "# check the shape of the dataframe\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>instruction</th>\n",
       "      <th>tuples</th>\n",
       "      <th>context.input</th>\n",
       "      <th>context.output</th>\n",
       "      <th>test_path</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Transform first and last names into username</td>\n",
       "      <td>format(): Combine first letter of first name w...</td>\n",
       "      <td>[{'input': 'john\tsmith', 'output': 'jsmith'}, ...</td>\n",
       "      <td>First and last names separated by a tab charac...</td>\n",
       "      <td>Username created by combining the first letter...</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>format()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extract name of actor/actress</td>\n",
       "      <td>extract(): extract name of actor/actress from ...</td>\n",
       "      <td>[{'input': '* '''1953 [[Meena Kumari]] – ''[[B...</td>\n",
       "      <td>text format containing movie details</td>\n",
       "      <td>extracted name of actor/actress</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>extract()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extract character names from wiki-style list</td>\n",
       "      <td>extract(): Extract the character name from the...</td>\n",
       "      <td>[{'input': '* '''1953 [[Meena Kumari]] – ''[[B...</td>\n",
       "      <td>Wiki-style list item containing actor and char...</td>\n",
       "      <td>Character name extracted from the input</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>extract()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>format date of birth</td>\n",
       "      <td>format(): convert YYYYMMDD to MM-DD-YYYY</td>\n",
       "      <td>[{'input': '19610223', 'output': '02-23-1961'}...</td>\n",
       "      <td>date in YYYYMMDD format</td>\n",
       "      <td>formatted date in MM-DD-YYYY</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>format()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Extract and format movie titles</td>\n",
       "      <td>transform(): Extract the movie title from the ...</td>\n",
       "      <td>[{'input': '* '''1953 [[Meena Kumari]] – ''[[B...</td>\n",
       "      <td>String containing movie information with title...</td>\n",
       "      <td>Lowercase movie title</td>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>transform()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           chat  \\\n",
       "0  Transform first and last names into username   \n",
       "1                 Extract name of actor/actress   \n",
       "2  Extract character names from wiki-style list   \n",
       "3                          format date of birth   \n",
       "4               Extract and format movie titles   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  format(): Combine first letter of first name w...   \n",
       "1  extract(): extract name of actor/actress from ...   \n",
       "2  extract(): Extract the character name from the...   \n",
       "3           format(): convert YYYYMMDD to MM-DD-YYYY   \n",
       "4  transform(): Extract the movie title from the ...   \n",
       "\n",
       "                                              tuples  \\\n",
       "0  [{'input': 'john\tsmith', 'output': 'jsmith'}, ...   \n",
       "1  [{'input': '* '''1953 [[Meena Kumari]] – ''[[B...   \n",
       "2  [{'input': '* '''1953 [[Meena Kumari]] – ''[[B...   \n",
       "3  [{'input': '19610223', 'output': '02-23-1961'}...   \n",
       "4  [{'input': '* '''1953 [[Meena Kumari]] – ''[[B...   \n",
       "\n",
       "                                       context.input  \\\n",
       "0  First and last names separated by a tab charac...   \n",
       "1               text format containing movie details   \n",
       "2  Wiki-style list item containing actor and char...   \n",
       "3                            date in YYYYMMDD format   \n",
       "4  String containing movie information with title...   \n",
       "\n",
       "                                      context.output  \\\n",
       "0  Username created by combining the first letter...   \n",
       "1                    extracted name of actor/actress   \n",
       "2            Character name extracted from the input   \n",
       "3                       formatted date in MM-DD-YYYY   \n",
       "4                              Lowercase movie title   \n",
       "\n",
       "                                           test_path     function  \n",
       "0  benchmark-FF-Trifacta-GoogleRefine/example_fil...     format()  \n",
       "1  benchmark-FF-Trifacta-GoogleRefine/example_fil...    extract()  \n",
       "2  benchmark-FF-Trifacta-GoogleRefine/example_fil...    extract()  \n",
       "3  benchmark-FF-Trifacta-GoogleRefine/example_fil...     format()  \n",
       "4  benchmark-FF-Trifacta-GoogleRefine/example_fil...  transform()  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TDE-v2 dataset Data Dictionary\n",
    "\n",
    "- The `chat` field represents a conversation between a user and an AI assistant. It is expected to be the input to the fine-tuned LM.\n",
    "\n",
    "- The `instruction` field represents a coding instruction with API-style `function` name that specifies the transformation type. It is expected to be the target output from the fine-tuned LM.\n",
    "\n",
    "- The `tuples` field represents a list of transformation-pairs, which serves as additional few-shot examples to help the fine-tuned LM to understand the user's intention. Each transformation-pair is a list of tuples, where each tuple contains an input and an output. The context of transformation pairs is stored in `context.input` and `context.output` fields, respectively.\n",
    "\n",
    "- `test_path` refers to the original path of the test case in the TDE dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat</th>\n",
       "      <th>instruction</th>\n",
       "      <th>tuples</th>\n",
       "      <th>context.input</th>\n",
       "      <th>context.output</th>\n",
       "      <th>test_path</th>\n",
       "      <th>function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chat, instruction, tuples, context.input, context.output, test_path, function]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates of instruction, and sort it\n",
    "df_all[df_all.duplicated(subset=['instruction'], keep=False)].sort_values(by='instruction')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extract()             57\n",
       "unit_convert()        48\n",
       "format()              45\n",
       "domain_calculate()    34\n",
       "transform()           25\n",
       "domain_map()          17\n",
       "Name: function, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show distribution of function\n",
    "df_all['function'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    226.000000\n",
      "mean       5.575221\n",
      "std        2.232309\n",
      "min        4.000000\n",
      "25%        5.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max       25.000000\n",
      "Name: num_tuples, dtype: float64\n",
      "Total number of tuples:  1260\n"
     ]
    }
   ],
   "source": [
    "# count the number of transformation-pairs in tuples\n",
    "df_all['num_tuples'] = df_all['tuples'].apply(len)\n",
    "print(df_all['num_tuples'].describe()) \n",
    "\n",
    "print(\"Total number of tuples: \", df_all['num_tuples'].sum())\n",
    "# show "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor to Alpaca Format\n",
    "\n",
    "The fine-tuned LM serves as an AI assistant to translate user chat into the target instruction (chat-to-instruction), with the help of transformation-pairs stored in `tuples` field and the context information stored in `context.input` and `context.output` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['chat', 'instruction', 'tuples', 'context.input', 'context.output',\n",
       "       'test_path', 'function', 'num_tuples'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Fine-Tuning Dataset\n",
    "\n",
    "Here we craft the fine-tuning dataset in Alpaca format. Regarding the above dataset, the *dataset description* in `dataset_info.json` of `LLaMA-Factory` should be the following options:\n",
    "\n",
    "1. `tde-o1`: chat-only\n",
    "\n",
    "```json\n",
    "\"tde-o1\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat\", // user chat\n",
    "    \"query\": \"\", // no human input\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "2. `tde-o2`: example-only\n",
    "\n",
    "```json\n",
    "\"tde-o2\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"\", // without user chat\n",
    "    \"query\": \"train_pairs\", // provide transformation-pairs\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "3. `tde-o3`: context-only\n",
    "\n",
    "```json\n",
    "\"tde-o3\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"\", // without user chat\n",
    "    \"query\": \"ctx\", // provide context\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "4. `tde-o4`: chat + example\n",
    "\n",
    "```json\n",
    "\"tde-o4\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat\", // user chat\n",
    "    \"query\": \"train_pairs\", // provide transformation-pairs\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "5. `tde-o5`: chat + context\n",
    "\n",
    "```json\n",
    "\"tde-o5\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat\", // user chat\n",
    "    \"query\": \"ctx\", // provide context\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "\n",
    "6. `tde-o6`: example + context\n",
    "\n",
    "```json\n",
    "\"tde-o6\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"\", // without user chat\n",
    "    \"query\": \"ctx_t_pairs\", // provide context + examples\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "7. `tde-o7`: chat + example + context\n",
    "\n",
    "```json\n",
    "\"tde-o7\": {\n",
    "  \"file_name\": \"tde-alpaca.json\",\n",
    "  \"columns\": {\n",
    "    \"prompt\": \"chat\", // user chat\n",
    "    \"query\": \"ctx_t_pairs\", // provide context + examples\n",
    "    \"response\": \"instruction\", // model response\n",
    "    \"system\": ...\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chat                   Transform first and last names into username\n",
       "instruction       format(): Combine first letter of first name w...\n",
       "tuples            [{'input': 'john\tsmith', 'output': 'jsmith'}, ...\n",
       "context.input     First and last names separated by a tab charac...\n",
       "context.output    Username created by combining the first letter...\n",
       "test_path         benchmark-FF-Trifacta-GoogleRefine/example_fil...\n",
       "function                                                   format()\n",
       "num_tuples                                                        5\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a sample of the dataframe\n",
    "df_all.iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chat` and `instruction` fields remain the same. We will refactor the `tuples` field into `io_pairs` field, and add `context.*` field to store the context information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_path</th>\n",
       "      <th>system</th>\n",
       "      <th>chat</th>\n",
       "      <th>instruction</th>\n",
       "      <th>ctx</th>\n",
       "      <th>train_pairs</th>\n",
       "      <th>ctx_t_pairs</th>\n",
       "      <th>test_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>You are an AI assistant that translates user c...</td>\n",
       "      <td>Transform first and last names into username</td>\n",
       "      <td>format(): Combine first letter of first name w...</td>\n",
       "      <td>Context information:\\nInput: First and last na...</td>\n",
       "      <td>Examples:\\nInput: john\\tsmith\\nOutput: jsmith\\...</td>\n",
       "      <td>Context information:\\nInput: First and last na...</td>\n",
       "      <td>Examples:\\nInput: alice\\tbob\\nOutput: abob\\nIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>You are an AI assistant that translates user c...</td>\n",
       "      <td>Extract name of actor/actress</td>\n",
       "      <td>extract(): extract name of actor/actress from ...</td>\n",
       "      <td>Context information:\\nInput: text format conta...</td>\n",
       "      <td>Examples:\\nInput: * '''1953 [[Meena Kumari]] –...</td>\n",
       "      <td>Context information:\\nInput: text format conta...</td>\n",
       "      <td>Examples:\\nInput: ** [[Geeta Bali]] – ''[[Vach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>You are an AI assistant that translates user c...</td>\n",
       "      <td>Extract character names from wiki-style list</td>\n",
       "      <td>extract(): Extract the character name from the...</td>\n",
       "      <td>Context information:\\nInput: Wiki-style list i...</td>\n",
       "      <td>Examples:\\nInput: * '''1953 [[Meena Kumari]] –...</td>\n",
       "      <td>Context information:\\nInput: Wiki-style list i...</td>\n",
       "      <td>Examples:\\nInput: ** [[Geeta Bali]] – ''[[Vach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>You are an AI assistant that translates user c...</td>\n",
       "      <td>format date of birth</td>\n",
       "      <td>format(): convert YYYYMMDD to MM-DD-YYYY</td>\n",
       "      <td>Context information:\\nInput: date in YYYYMMDD ...</td>\n",
       "      <td>Examples:\\nInput: 19610223\\nOutput: 02-23-1961...</td>\n",
       "      <td>Context information:\\nInput: date in YYYYMMDD ...</td>\n",
       "      <td>Examples:\\nInput: 19221213\\nOutput: 12-13-1922...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benchmark-FF-Trifacta-GoogleRefine/example_fil...</td>\n",
       "      <td>You are an AI assistant that translates user c...</td>\n",
       "      <td>Extract and format movie titles</td>\n",
       "      <td>transform(): Extract the movie title from the ...</td>\n",
       "      <td>Context information:\\nInput: String containing...</td>\n",
       "      <td>Examples:\\nInput: * '''1953 [[Meena Kumari]] –...</td>\n",
       "      <td>Context information:\\nInput: String containing...</td>\n",
       "      <td>Examples:\\nInput: ** [[Geeta Bali]] – ''[[Vach...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           test_path  \\\n",
       "0  benchmark-FF-Trifacta-GoogleRefine/example_fil...   \n",
       "1  benchmark-FF-Trifacta-GoogleRefine/example_fil...   \n",
       "2  benchmark-FF-Trifacta-GoogleRefine/example_fil...   \n",
       "3  benchmark-FF-Trifacta-GoogleRefine/example_fil...   \n",
       "4  benchmark-FF-Trifacta-GoogleRefine/example_fil...   \n",
       "\n",
       "                                              system  \\\n",
       "0  You are an AI assistant that translates user c...   \n",
       "1  You are an AI assistant that translates user c...   \n",
       "2  You are an AI assistant that translates user c...   \n",
       "3  You are an AI assistant that translates user c...   \n",
       "4  You are an AI assistant that translates user c...   \n",
       "\n",
       "                                           chat  \\\n",
       "0  Transform first and last names into username   \n",
       "1                 Extract name of actor/actress   \n",
       "2  Extract character names from wiki-style list   \n",
       "3                          format date of birth   \n",
       "4               Extract and format movie titles   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  format(): Combine first letter of first name w...   \n",
       "1  extract(): extract name of actor/actress from ...   \n",
       "2  extract(): Extract the character name from the...   \n",
       "3           format(): convert YYYYMMDD to MM-DD-YYYY   \n",
       "4  transform(): Extract the movie title from the ...   \n",
       "\n",
       "                                                 ctx  \\\n",
       "0  Context information:\\nInput: First and last na...   \n",
       "1  Context information:\\nInput: text format conta...   \n",
       "2  Context information:\\nInput: Wiki-style list i...   \n",
       "3  Context information:\\nInput: date in YYYYMMDD ...   \n",
       "4  Context information:\\nInput: String containing...   \n",
       "\n",
       "                                         train_pairs  \\\n",
       "0  Examples:\\nInput: john\\tsmith\\nOutput: jsmith\\...   \n",
       "1  Examples:\\nInput: * '''1953 [[Meena Kumari]] –...   \n",
       "2  Examples:\\nInput: * '''1953 [[Meena Kumari]] –...   \n",
       "3  Examples:\\nInput: 19610223\\nOutput: 02-23-1961...   \n",
       "4  Examples:\\nInput: * '''1953 [[Meena Kumari]] –...   \n",
       "\n",
       "                                         ctx_t_pairs  \\\n",
       "0  Context information:\\nInput: First and last na...   \n",
       "1  Context information:\\nInput: text format conta...   \n",
       "2  Context information:\\nInput: Wiki-style list i...   \n",
       "3  Context information:\\nInput: date in YYYYMMDD ...   \n",
       "4  Context information:\\nInput: String containing...   \n",
       "\n",
       "                                          test_pairs  \n",
       "0  Examples:\\nInput: alice\\tbob\\nOutput: abob\\nIn...  \n",
       "1  Examples:\\nInput: ** [[Geeta Bali]] – ''[[Vach...  \n",
       "2  Examples:\\nInput: ** [[Geeta Bali]] – ''[[Vach...  \n",
       "3  Examples:\\nInput: 19221213\\nOutput: 12-13-1922...  \n",
       "4  Examples:\\nInput: ** [[Geeta Bali]] – ''[[Vach...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refactor columns based on Alpaca format\n",
    "df_alpaca = df_all.copy()\n",
    "\n",
    "# set system prompt\n",
    "df_alpaca['system'] = \"You are an AI assistant that translates user chat into the target instruction.\"\n",
    "\n",
    "# context information\n",
    "df_alpaca['ctx'] = df_alpaca.apply(lambda x: 'Context information:\\n' +\n",
    "                                   'Input: ' + x['context.input'] + '\\n' + \n",
    "                                   'Output: ' + x['context.output'],axis=1)\n",
    "\n",
    "# transformation pairs, split train and test pairs, top 3 for train, last for test\n",
    "df_alpaca['train_pairs'] = df_alpaca['tuples'].apply(lambda x: 'Examples:\\n' +\n",
    "                                               '\\n'.join([f'Input: {t[\"input\"]}\\nOutput: {t[\"output\"]}' for t in x[:3]]))\n",
    "\n",
    "df_alpaca['test_pairs'] = df_alpaca['tuples'].apply(lambda x: 'Examples:\\n' +\n",
    "                                               '\\n'.join([f'Input: {t[\"input\"]}\\nOutput: {t[\"output\"]}' for t in x[3:]]))\n",
    "\n",
    "\n",
    "# ctx + train_pairs\n",
    "df_alpaca['ctx_t_pairs'] = df_alpaca['ctx'] + '\\n\\n' + df_alpaca['train_pairs']\n",
    "\n",
    "# slice columns\n",
    "df_alpaca = df_alpaca[['test_path', 'system', 'chat', 'instruction', 'ctx', 'train_pairs', 'ctx_t_pairs', 'test_pairs']]\n",
    "\n",
    "\n",
    "df_alpaca.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat:\n",
      "Transform first and last names into username\n",
      "\n",
      "Instruction:\n",
      "format(): Combine first letter of first name with full last name to create username\n",
      "\n",
      "Test Path:\n",
      "benchmark-FF-Trifacta-GoogleRefine/example_file_name\n",
      "\n",
      "System:\n",
      "You are an AI assistant that translates user chat into the target instruction.\n",
      "\n",
      "Context and Pairs:\n",
      "Context information:\n",
      "Input: First and last names separated by a tab character.\n",
      "Output: Username created by combining the first letter of the first name with the full last name.\n",
      "\n",
      "Examples:\n",
      "Input: john\tsmith\n",
      "Output: jsmith\n",
      "Input: adam\twilliams\n",
      "Output: awilliams\n",
      "Input: james\tjohnson\n",
      "Output: jjohnson\n"
     ]
    }
   ],
   "source": [
    "# Print all details of the first row in df_alpaca\n",
    "print(\"Chat:\")\n",
    "print(df_alpaca.iloc[0]['chat'])\n",
    "print(\"\\nInstruction:\")\n",
    "print(df_alpaca.iloc[0]['instruction'])\n",
    "print(\"\\nTest Path:\")\n",
    "print(df_alpaca.iloc[0]['test_path'])\n",
    "print(\"\\nSystem:\")\n",
    "print(df_alpaca.iloc[0]['system'])\n",
    "print(\"\\nContext and Pairs:\")\n",
    "print(df_alpaca.iloc[0]['ctx_t_pairs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to JSON\n",
    "df_alpaca.to_json('../data/TDE-alpaca/tde-alpaca.json', orient='records', indent=4, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-sketch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
