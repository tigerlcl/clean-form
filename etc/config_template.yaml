# module config
chat_to_inst: true
n_shot: 3
prompt_mode: "chat_example" # Can use chat, ctx, example as keywords to control the prompt

# vLLM for FT model
vllm_model: "./models/llama3_lora_sft"
vllm_cfg:
  base_url: "http://localhost:8000/v1"
  api_key: "token-abc123"

# OPENAI
openai_model: "gpt-4o-mini"
openai_cfg:
  base_url: "https://api.openai.com/v1"
  api_key: "sk-xxx"
